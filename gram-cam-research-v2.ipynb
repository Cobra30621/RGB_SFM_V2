{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T06:50:48.663435Z",
     "start_time": "2025-03-24T06:50:42.351281Z"
    }
   },
   "source": [
    "# 讀取模型\n",
    "from config import *\n",
    "\n",
    "from load_tools import load_model_and_data\n",
    "\n",
    "checkpoint_filename = 'RGB_SFMCNN_V2_best'\n",
    "model, train_dataloader, test_dataloader, images, labels = load_model_and_data(checkpoint_filename)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code/runs/train/exp\n",
      "torch.Size([900, 3, 28, 28]) torch.Size([900, 9])\n",
      "triangle\n",
      "cReLU_percent\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        RGB_Conv2d-1             [-1, 30, 6, 6]               0\n",
      "        RGB_Conv2d-2             [-1, 30, 6, 6]               0\n",
      "          triangle-3             [-1, 30, 6, 6]               0\n",
      "          triangle-4             [-1, 30, 6, 6]               0\n",
      "     cReLU_percent-5             [-1, 30, 6, 6]               0\n",
      "     cReLU_percent-6             [-1, 30, 6, 6]               0\n",
      "               SFM-7             [-1, 30, 3, 3]               0\n",
      "        RBF_Conv2d-8            [-1, 225, 3, 3]           6,750\n",
      "     cReLU_percent-9            [-1, 225, 3, 3]               0\n",
      "              SFM-10            [-1, 225, 3, 1]               0\n",
      "       RBF_Conv2d-11            [-1, 625, 3, 1]         140,625\n",
      "    cReLU_percent-12            [-1, 625, 3, 1]               0\n",
      "      Gray_Conv2d-13             [-1, 70, 6, 6]           1,750\n",
      "      Gray_Conv2d-14             [-1, 70, 6, 6]           1,750\n",
      "    cReLU_percent-15             [-1, 70, 6, 6]               0\n",
      "    cReLU_percent-16             [-1, 70, 6, 6]               0\n",
      "              SFM-17             [-1, 70, 3, 3]               0\n",
      "       RBF_Conv2d-18            [-1, 625, 3, 3]          43,750\n",
      "    cReLU_percent-19            [-1, 625, 3, 3]               0\n",
      "              SFM-20            [-1, 625, 3, 1]               0\n",
      "       RBF_Conv2d-21           [-1, 1225, 3, 1]         765,625\n",
      "    cReLU_percent-22           [-1, 1225, 3, 1]               0\n",
      "           Linear-23                    [-1, 9]          49,959\n",
      "================================================================\n",
      "Total params: 1,010,209\n",
      "Trainable params: 1,010,209\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 3.85\n",
      "Estimated Total Size (MB): 4.22\n",
      "----------------------------------------------------------------\n",
      "RGB_SFMCNN_V2(\n",
      "  (RGB_conv2d): Sequential(\n",
      "    (0): RGB_Conv2d(initial = uniform, weight shape = torch.Size([30, 3]), cal_dist = LAB)\n",
      "    (1): triangle(w = 1.0)\n",
      "    (2): cReLU_percent(percent=0.30000001192092896)\n",
      "  )\n",
      "  (GRAY_conv2d): Sequential(\n",
      "    (0): Gray_Conv2d(initial = kaiming, weight shape = (70, 1, 5, 5))\n",
      "    (1): cReLU_percent(percent=0.30000001192092896)\n",
      "  )\n",
      "  (RGB_convs): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): RGB_Conv2d(initial = uniform, weight shape = torch.Size([30, 3]), cal_dist = LAB)\n",
      "      (1): triangle(w = 1.0)\n",
      "      (2): cReLU_percent(percent=0.30000001192092896)\n",
      "    )\n",
      "    (1): SFM(\n",
      "      filter=(2, 2), method=alpha_mean, alpha=[[1.         0.96666664]\n",
      "       [0.93333334 0.9       ]]\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): RBF_Conv2d(initial = kaiming, weight shape = (225, 30, 1, 1))\n",
      "      (1): cReLU_percent(percent=0.4000000059604645)\n",
      "      (2): SFM(filter=(1, 3), method=alpha_mean, alpha=[[1.   0.95 0.9 ]])\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): RBF_Conv2d(initial = kaiming, weight shape = (625, 225, 1, 1))\n",
      "      (1): cReLU_percent(percent=0.5)\n",
      "    )\n",
      "  )\n",
      "  (Gray_convs): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Gray_Conv2d(initial = kaiming, weight shape = (70, 1, 5, 5))\n",
      "      (1): cReLU_percent(percent=0.30000001192092896)\n",
      "    )\n",
      "    (1): SFM(\n",
      "      filter=(2, 2), method=alpha_mean, alpha=[[1.         0.96666664]\n",
      "       [0.93333334 0.9       ]]\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): RBF_Conv2d(initial = kaiming, weight shape = (625, 70, 1, 1))\n",
      "      (1): cReLU_percent(percent=0.4000000059604645)\n",
      "      (2): SFM(filter=(1, 3), method=alpha_mean, alpha=[[1.   0.95 0.9 ]])\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): RBF_Conv2d(initial = kaiming, weight shape = (1225, 625, 1, 1))\n",
      "      (1): cReLU_percent(percent=0.5)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=5550, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "Test Accuracy: 0.9966666666666667\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:52:42.293438Z",
     "start_time": "2025-03-24T06:52:40.539418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pytorch_grad_cam import ( GradCAM, HiResCAM, GradCAMPlusPlus,\n",
    "                              GradCAMElementWise, XGradCAM, AblationCAM, ScoreCAM, EigenCAM, EigenGradCAM,\n",
    "                              LayerCAM, KPCA_CAM)\n",
    "\n",
    "# 繪製熱圖\n",
    "PLOT_HEATMAP = True\n",
    "\n",
    "FMs = {}\n",
    "if arch['args']['in_channels'] == 1:\n",
    "    FMs[0] = model.convs[0][0].weight.reshape(-1, *arch['args']['Conv2d_kernel'][0], 1)\n",
    "    print(f'FM[0] shape: {FMs[0].shape}')\n",
    "    FMs[1] = model.convs[1][0].weight.reshape(-1, int(model.convs[1][0].weight.shape[1] ** 0.5),\n",
    "                                              int(model.convs[1][0].weight.shape[1] ** 0.5), 1)\n",
    "    print(f'FM[1] shape: {FMs[1].shape}')\n",
    "    FMs[2] = model.convs[2][0].weight.reshape(-1, int(model.convs[2][0].weight.shape[1] ** 0.5),\n",
    "                                              int(model.convs[2][0].weight.shape[1] ** 0.5), 1)\n",
    "    print(f'FM[2] shape: {FMs[2].shape}')\n",
    "    FMs[3] = model.convs[3][0].weight.reshape(-1, int(model.convs[3][0].weight.shape[1] ** 0.5),\n",
    "                                              int(model.convs[3][0].weight.shape[1] ** 0.5), 1)\n",
    "    print(f'FM[3] shape: {FMs[3].shape}')\n",
    "else:\n",
    "    # 平行架構\n",
    "    kernel_size = arch['args']['Conv2d_kernel'][0]\n",
    "    weights = torch.concat([model.RGB_convs[0][0].transform_weights()])\n",
    "    weights = weights.reshape(arch['args']['channels'][0][0], arch['args']['in_channels'], 1, 1)\n",
    "    weights = weights.repeat(1, 1, *kernel_size)\n",
    "    FMs['RGB_convs_0'] = weights\n",
    "    print(f'FM[RGB_convs_0] shape: {FMs[\"RGB_convs_0\"].shape}')\n",
    "\n",
    "    FMs['RGB_convs_1'] = model.RGB_convs[2][0].weight.reshape(-1, 2, 15, 1)\n",
    "    print(f'FM[RGB_convs_1] shape: {FMs[\"RGB_convs_1\"].shape}')\n",
    "\n",
    "    FMs['RGB_convs_2'] = model.RGB_convs[3][0].weight.reshape(-1, int(model.RGB_convs[3][0].weight.shape[1] ** 0.5),\n",
    "                                                              int(model.RGB_convs[3][0].weight.shape[1] ** 0.5), 1)\n",
    "    print(f'FM[RGB_convs_2] shape: {FMs[\"RGB_convs_2\"].shape}')\n",
    "\n",
    "    FMs['Gray_convs_0'] = model.Gray_convs[0][0].weight.reshape(arch['args']['channels'][1][0], 1, *kernel_size)\n",
    "    print(f'FM[Gray_convs_0] shape: {FMs[\"Gray_convs_0\"].shape}')\n",
    "    FMs['Gray_convs_1'] = model.Gray_convs[2][0].weight.reshape(-1, 7, 10, 1)\n",
    "    print(f'FM[Gray_convs_1] shape: {FMs[\"Gray_convs_1\"].shape}')\n",
    "    FMs['Gray_convs_2'] = model.Gray_convs[3][0].weight.reshape(-1, int(model.Gray_convs[3][0].weight.shape[1] ** 0.5),\n",
    "                                                                int(model.Gray_convs[3][0].weight.shape[1] ** 0.5), 1)\n",
    "    print(f'FM[Gray_convs_2] shape: {FMs[\"Gray_convs_2\"].shape}')\n",
    "\n",
    "layers = get_layers(model)\n",
    "\n",
    "CIs = {}\n",
    "kernel_size = arch['args']['Conv2d_kernel'][0]\n",
    "stride = (arch['args']['strides'][0], arch['args']['strides'][0])\n",
    "if arch['args']['in_channels'] == 1:\n",
    "    CIs[0], CI_idx, CI_values = get_ci(images, layers[0], kernel_size=kernel_size, stride=stride)\n",
    "    CIs[1], CI_idx, CI_values = get_ci(images, layers[1], kernel_size=kernel_size, stride=stride,\n",
    "                                       sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:1]), dim=0))\n",
    "    CIs[2], CI_idx, CI_values = get_ci(images, layers[2], kernel_size=kernel_size, stride=stride,\n",
    "                                       sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:2]), dim=0))\n",
    "    CIs[3], CI_idx, CI_values = get_ci(images, layers[3], kernel_size=kernel_size, stride=stride,\n",
    "                                       sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:3]), dim=0))\n",
    "else:\n",
    "\n",
    "    CIs[\"RGB_convs_0\"], CI_idx, CI_values = get_ci(images, layers['RGB_convs_0'], kernel_size, stride=stride)\n",
    "    CIs[\"RGB_convs_1\"], CI_idx, CI_values = get_ci(images, layers[\"RGB_convs_1\"], kernel_size=kernel_size,\n",
    "                                                   stride=stride,\n",
    "                                                   sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:1]),\n",
    "                                                                         dim=0))\n",
    "    CIs[\"RGB_convs_2\"], CI_idx, CI_values = get_ci(images, layers[\"RGB_convs_2\"], kernel_size=kernel_size,\n",
    "                                                   stride=stride,\n",
    "                                                   sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:2]),\n",
    "                                                                         dim=0))\n",
    "\n",
    "    CIs[\"Gray_convs_0\"], CI_idx, CI_values = get_ci(model.gray_transform(images), layers['Gray_convs_0'], kernel_size,\n",
    "                                                    stride=stride)\n",
    "    CIs[\"Gray_convs_1\"], CI_idx, CI_values = get_ci(model.gray_transform(images), layers[\"Gray_convs_1\"],\n",
    "                                                    kernel_size=kernel_size, stride=stride,\n",
    "                                                    sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:1]),\n",
    "                                                                          dim=0))\n",
    "    CIs[\"Gray_convs_2\"], CI_idx, CI_values = get_ci(model.gray_transform(images), layers[\"Gray_convs_2\"],\n",
    "                                                    kernel_size=kernel_size, stride=stride,\n",
    "                                                    sfm_filter=torch.prod(torch.tensor(arch['args']['SFM_filters'][:2]),\n",
    "                                                                          dim=0))\n",
    "\n",
    "if config['dataset'] == 'Colored_MNIST' or config['dataset'] == 'Colored_FashionMNIST':\n",
    "    label_to_idx = {}\n",
    "    i = 0\n",
    "    for c in ['red', 'green', 'blue']:\n",
    "        for n in range(10):\n",
    "            label_to_idx[c + '_' + str(n)] = i\n",
    "            i += 1\n",
    "    idx_to_label = {value: key for key, value in label_to_idx.items()}\n",
    "elif config['dataset'] == 'AnotherColored_MNIST' or config['dataset'] == 'AnotherColored_FashionMNIST':\n",
    "    label_to_idx = {}\n",
    "    colors = {\n",
    "        'brown': [151, 74, 0],\n",
    "        'light_blue': [121, 196, 208],\n",
    "        'light_pink': [221, 180, 212]\n",
    "    }\n",
    "    i = 0\n",
    "    for c in colors.keys():\n",
    "        for n in range(10):\n",
    "            label_to_idx[c + '_' + str(n)] = i\n",
    "            i += 1\n",
    "    idx_to_label = {value: key for key, value in label_to_idx.items()}\n",
    "\n",
    "example_num = 450\n",
    "\n",
    "\n"
   ],
   "id": "b68cc2179aed5302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM[RGB_convs_0] shape: torch.Size([30, 3, 5, 5])\n",
      "FM[RGB_convs_1] shape: torch.Size([225, 2, 15, 1])\n",
      "FM[RGB_convs_2] shape: torch.Size([625, 15, 15, 1])\n",
      "FM[Gray_convs_0] shape: torch.Size([70, 1, 5, 5])\n",
      "FM[Gray_convs_1] shape: torch.Size([625, 7, 10, 1])\n",
      "FM[Gray_convs_2] shape: torch.Size([1225, 25, 25, 1])\n",
      "segments shape: torch.Size([32400, 5, 5, 3])\n",
      "output shape: torch.Size([32400, 30])\n",
      "segments shape: torch.Size([8100, 10, 10, 3])\n",
      "output shape: torch.Size([8100, 225])\n",
      "segments shape: torch.Size([2700, 10, 30, 3])\n",
      "output shape: torch.Size([2700, 625])\n",
      "segments shape: torch.Size([32400, 5, 5, 1])\n",
      "output shape: torch.Size([32400, 70])\n",
      "segments shape: torch.Size([8100, 10, 10, 1])\n",
      "output shape: torch.Size([8100, 625])\n",
      "segments shape: torch.Size([2700, 10, 30, 1])\n",
      "output shape: torch.Size([2700, 1225])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:53:45.681807Z",
     "start_time": "2025-03-24T06:53:45.671748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import plot_map\n",
    "\n",
    "\n",
    "# 繪製反應 RM 圖，並存到陣列中\n",
    "def plot_RM_then_save(layer_num, plot_shape, img, save_path, is_gray = False, figs = None):\n",
    "    fig = plot_RM_map(layer_num, plot_shape, img, save_path, is_gray)\n",
    "\n",
    "    if figs is not None:\n",
    "        figs[layer_num] = fig\n",
    "\n",
    "# 繪製反應 RM 圖\n",
    "def plot_RM_map(layer_num, plot_shape, img, save_path, is_gray = False):\n",
    "\n",
    "    if is_gray:\n",
    "        RM = layers[layer_num](model.gray_transform(img.unsqueeze(0)))[0]\n",
    "    else:\n",
    "        RM = layers[layer_num](img.unsqueeze(0))[0]\n",
    "\n",
    "    # print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "\n",
    "    RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "    return plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "             path=save_path + f'{layer_num}_RM')\n",
    "\n",
    "\n",
    "save_path = f'./detect/{config[\"dataset\"]}_{checkpoint_filename}/example'\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)  # 刪除資料夾及其內容\n",
    "    os.makedirs(save_path)  # 重新建立資料夾\n"
   ],
   "id": "c3a716d32aaa6428",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:53:48.186526Z",
     "start_time": "2025-03-24T06:53:48.129121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_image(image, label, test_id):\n",
    "    print(test_id)\n",
    "    save_path = f'./detect/{config[\"dataset\"]}_{checkpoint_filename}/example/{label.argmax().item()}/example_{test_id}/'\n",
    "    RM_save_path = f'{save_path}/RMs/'\n",
    "    RM_CI_save_path = f'{save_path}/RM_CIs/'\n",
    "    os.makedirs(RM_save_path, exist_ok=True)\n",
    "    os.makedirs(RM_CI_save_path, exist_ok=True)\n",
    "\n",
    "    if arch['args']['in_channels'] == 1:\n",
    "        torchvision.utils.save_image(image, save_path + f'origin_{test_id}.png')\n",
    "    else:\n",
    "        plt.imsave(save_path + f'origin_{test_id}.png', image.permute(1, 2, 0).detach().numpy())\n",
    "\n",
    "    segments = split(image.unsqueeze(0), kernel_size=arch['args']['Conv2d_kernel'][0],\n",
    "                     stride=(arch['args']['strides'][0], arch['args']['strides'][0]))[0]\n",
    "\n",
    "    RM_CIs = {}\n",
    "\n",
    "    RM_figs = {}\n",
    "\n",
    "    RM_CI_figs = {}\n",
    "\n",
    "    fig = plot_map(segments.permute(1, 2, 3, 4, 0), path=save_path + f'origin_split_{test_id}.png')\n",
    "    RM_figs['Origin_Split'] = fig\n",
    "    RM_CI_figs['Origin_Split'] =  fig\n",
    "\n",
    "    if arch['args']['in_channels'] == 1:\n",
    "        # Layer 0\n",
    "        layer_num = 0\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5),\n",
    "                                             1).detach().numpy(), path=RM_save_path + f'{layer_num}_RM')\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, 1)\n",
    "        plot_map(RM_CI.detach().numpy(), path=RM_CI_save_path + f'Layer{layer_num}_RM_CI', cmap='gray')\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "\n",
    "        # Layer 1\n",
    "        layer_num = 1\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5),\n",
    "                                             1).detach().numpy(), path=RM_save_path + f'{layer_num}_RM')\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, arch['args'][\n",
    "                                                                                                       'in_channels'])\n",
    "        plot_map(RM_CI.detach().numpy(), path=RM_CI_save_path + f'Layer{layer_num}_RM_CI', cmap='gray')\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "\n",
    "        # Layer 2\n",
    "        layer_num = 2\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5),\n",
    "                                             1).detach().numpy(), path=RM_save_path + f'{layer_num}_RM')\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, arch['args'][\n",
    "                                                                                                       'in_channels'])\n",
    "        plot_map(RM_CI.detach().numpy(), path=RM_CI_save_path + f'Layer{layer_num}_RM_CI', cmap='gray')\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "\n",
    "        # Layer 3\n",
    "        layer_num = 3\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5),\n",
    "                                             1).detach().numpy(), path=RM_save_path + f'{layer_num}_RM')\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, arch['args'][\n",
    "                                                                                                       'in_channels'])\n",
    "        plot_map(RM_CI.detach().numpy(), path=RM_CI_save_path + f'Layer{layer_num}_RM_CI', cmap='gray')\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "\n",
    "\n",
    "    else:\n",
    "        ################################### RGB ###################################\n",
    "        ### RGB_convs_0 ###\n",
    "        # 跑完響應模組，SFM 合併前\n",
    "        layer_num = 'RGB_convs_0'\n",
    "        plot_shape = (5, 6)\n",
    "\n",
    "        # 繪製只跑 Conv(卷積) 的 RM\n",
    "        plot_RM_then_save('RGB_convs_0_Conv', plot_shape, image, RM_save_path,\n",
    "                          False, RM_figs)\n",
    "\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        FM_H, FM_W = FMs[layer_num].shape[2], FMs[layer_num].shape[3]\n",
    "        RM_FM = FMs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].permute(0, 2, 3, 1).reshape(\n",
    "            RM_H, RM_W, FM_H, FM_W, arch['args']['in_channels'])\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, arch['args'][\n",
    "                                                                                                       'in_channels'])\n",
    "        RM_CI_figs[layer_num] = plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI_origin')\n",
    "        RM_CI = RM_CI.permute(0, 1, 4, 2, 3).reshape(*RM_CI.shape[:2], arch['args']['in_channels'], -1).mean(\n",
    "            dim=-1).unsqueeze(-2).unsqueeze(-2).repeat(1, 1, *RM_CI.shape[2:4], 1)\n",
    "\n",
    "\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "        # 繪製 RM\n",
    "        fig = plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "                 path=RM_save_path + f'{layer_num}_RM')\n",
    "        RM_figs[layer_num] = fig\n",
    "\n",
    "\n",
    "        plot_map(RM_FM.detach().numpy(), path=RM_CI_save_path + f'{layer_num}_RM_FM')\n",
    "        plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI')\n",
    "\n",
    "\n",
    "        # 繪製 SFM 合併後的 RM\n",
    "        plot_RM_then_save('RGB_convs_0_SFM', plot_shape, image, RM_save_path,\n",
    "                          False, RM_figs)\n",
    "\n",
    "        ### RGB_convs_1 ###\n",
    "        # 跑完響應模組，SFM 合併前\n",
    "        layer_num = 'RGB_convs_1'\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        plot_shape = (int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5))\n",
    "        # 繪製 只跑 Conv(卷積) 的 RM\n",
    "        plot_RM_then_save('RGB_convs_1_Conv', plot_shape, image, RM_save_path,\n",
    "                          False, RM_figs)\n",
    "\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        # 存RM_FM、RM_CI\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, arch['args'][\n",
    "                                                                                                       'in_channels'])\n",
    "        RM_CI_figs[layer_num] = plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI_origin')\n",
    "        # 將RM_CI取每個小圖的代表色塊後合併成為新的RM_CI\n",
    "        RM_CI = RM_CI.reshape(RM_H, RM_W, CI_H // RM_CIs['RGB_convs_0'].shape[2], RM_CIs['RGB_convs_0'].shape[2],\n",
    "                              CI_W // RM_CIs['RGB_convs_0'].shape[3], RM_CIs['RGB_convs_0'].shape[3],\n",
    "                              arch['args']['in_channels'])\n",
    "        RM_CI = RM_CI.permute(0, 2, 1, 4, 3, 5, 6)\n",
    "        RM_CI = RM_CI.reshape(RM_CIs['RGB_convs_0'].shape)\n",
    "        RM_CI = RM_CI.permute(0, 1, 4, 2, 3).reshape(*RM_CI.shape[:2], arch['args']['in_channels'], -1).mean(\n",
    "            dim=-1).unsqueeze(-2).unsqueeze(-2).repeat(1, 1, *RM_CI.shape[2:4], 1)\n",
    "        RM_CI = RM_CI.reshape(RM_H, RM_CI.shape[0] // RM_H, RM_W, RM_CI.shape[1] // RM_W, *RM_CI.shape[2:])\n",
    "        RM_CI = RM_CI.permute(0, 2, 1, 4, 3, 5, 6).reshape(RM_H, RM_W, CI_H, CI_W, 3)\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "        plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI')\n",
    "        # 繪製 RM\n",
    "        fig = plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "                 path=RM_save_path + f'{layer_num}_RM')\n",
    "        RM_figs[layer_num] = fig\n",
    "\n",
    "\n",
    "        # 繪製 SFM 合併後的 RM\n",
    "        plot_RM_then_save('RGB_convs_1_SFM', plot_shape, image, RM_save_path,\n",
    "                          False, RM_figs)\n",
    "\n",
    "        ### RGB_convs_2\n",
    "        # 跑完響應模組，SFM 合併前\n",
    "        layer_num = 'RGB_convs_2'\n",
    "        RM = layers[layer_num](image.unsqueeze(0))[0]\n",
    "        plot_shape = (int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5))\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        # 繪製只跑 Conv(卷積) 的 RM\n",
    "        plot_RM_then_save('RGB_convs_2_Conv', plot_shape, image, RM_save_path,\n",
    "                          False, RM_figs)\n",
    "\n",
    "        # 存RM_FM、RM_CI\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, arch['args'][\n",
    "                                                                                                       'in_channels'])\n",
    "        RM_CI_figs[layer_num] = plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI_origin')\n",
    "        # 將RM_CI取每個小圖的代表色塊後合併成為新的RM_CI\n",
    "        RM_CI = RM_CI.reshape(RM_H, RM_W, CI_H // RM_CIs['RGB_convs_0'].shape[2], RM_CIs['RGB_convs_0'].shape[2],\n",
    "                              CI_W // RM_CIs['RGB_convs_0'].shape[3], RM_CIs['RGB_convs_0'].shape[3],\n",
    "                              arch['args']['in_channels'])\n",
    "        RM_CI = RM_CI.permute(0, 2, 1, 4, 3, 5, 6)\n",
    "        RM_CI = RM_CI.reshape(RM_CIs['RGB_convs_0'].shape)\n",
    "        RM_CI = RM_CI.permute(0, 1, 4, 2, 3).reshape(*RM_CI.shape[:2], arch['args']['in_channels'], -1).mean(\n",
    "            dim=-1).unsqueeze(-2).unsqueeze(-2).repeat(1, 1, *RM_CI.shape[2:4], 1)\n",
    "        RM_CI = RM_CI.reshape(RM_H, RM_CI.shape[0] // RM_H, RM_W, RM_CI.shape[1] // RM_W, *RM_CI.shape[2:])\n",
    "        RM_CI = RM_CI.permute(0, 2, 1, 4, 3, 5, 6).reshape(RM_H, RM_W, CI_H, CI_W, 3)\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "        plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI')\n",
    "        # 繪製 RM\n",
    "        fig = plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "                       path=RM_save_path + f'{layer_num}_RM')\n",
    "        RM_figs[layer_num] = fig\n",
    "\n",
    "        ################################### Gray ###################################\n",
    "        ### Gray_convs_0 ###\n",
    "        # 跑完響應模組，SFM 合併前\n",
    "        layer_num = 'Gray_convs_0'\n",
    "        plot_shape = (7, 10)\n",
    "        RM = layers[layer_num](model.gray_transform(image.unsqueeze(0)))[0]\n",
    "        print(f\"{layer_num}_RM: {RM.shape}\")\n",
    "        # 存RM_FM、RM_CI\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, 1)\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "                 path=RM_save_path + f'{layer_num}_RM')\n",
    "        RM_CI_figs[layer_num] = plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI', cmap='gray')\n",
    "\n",
    "        # 只跑 Conv(卷積)\n",
    "        plot_RM_map('Gray_convs_0_Conv', plot_shape, image, RM_save_path, is_gray = True)\n",
    "        # SFM 合併後\n",
    "        plot_RM_map('Gray_convs_0_SFM', plot_shape, image, RM_save_path, is_gray = True)\n",
    "\n",
    "\n",
    "        ### Gray_convs_1 ###\n",
    "        # 跑完響應模組，SFM 合併前\n",
    "        layer_num = 'Gray_convs_1'\n",
    "        RM = layers[layer_num](model.gray_transform(image.unsqueeze(0)))[0]\n",
    "        plot_shape = (int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5))\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        # 存RM_FM、RM_CI\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, 1)\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "                 path=RM_save_path + f'{layer_num}_RM')\n",
    "        RM_CI_figs[layer_num] = plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI', cmap='gray')\n",
    "\n",
    "        # 只跑 Conv(卷積)\n",
    "        plot_RM_map('Gray_convs_1_Conv', plot_shape, image, RM_save_path, is_gray=True)\n",
    "        # SFM 合併後\n",
    "        plot_RM_map('Gray_convs_1_SFM', plot_shape, image, RM_save_path, is_gray=True)\n",
    "\n",
    "\n",
    "        ### Gray_convs_2 ###\n",
    "        # 跑完響應模組，SFM 合併前\n",
    "        layer_num = 'Gray_convs_2'\n",
    "        RM = layers[layer_num](model.gray_transform(image.unsqueeze(0)))[0]\n",
    "        plot_shape = (int(RM.shape[0] ** 0.5), int(RM.shape[0] ** 0.5))\n",
    "        print(f\"Layer{layer_num}_RM: {RM.shape}\")\n",
    "        # 存RM_FM、RM_CI\n",
    "        RM_H, RM_W = RM.shape[1], RM.shape[2]\n",
    "        CI_H, CI_W = CIs[layer_num].shape[2], CIs[layer_num].shape[3]\n",
    "        RM_CI = CIs[layer_num][torch.topk(RM, k=1, dim=0, largest=True).indices.flatten()].reshape(RM_H, RM_W, CI_H,\n",
    "                                                                                                   CI_W, 1)\n",
    "        RM_CIs[layer_num] = RM_CI\n",
    "        plot_map(RM.permute(1, 2, 0).reshape(RM_H, RM_W, *plot_shape, 1).detach().numpy(),\n",
    "                 path=RM_save_path + f'{layer_num}_RM')\n",
    "        RM_CI_figs[layer_num] =plot_map(RM_CI, path=RM_CI_save_path + f'{layer_num}_RM_CI', cmap='gray')\n",
    "\n",
    "        # 只跑 Conv(卷積)\n",
    "        plot_RM_map('Gray_convs_2_Conv', plot_shape, image, RM_save_path, is_gray=True)\n",
    "\n",
    "        plot_combine_images(RM_figs, RM_save_path + f'RGB_combine')\n",
    "        plot_combine_images(RM_CI_figs, RM_CI_save_path + f'combine')\n",
    "\n",
    "        ################################### heatmap ###################################\n",
    "\n",
    "    plt.close('all')\n",
    "    \n",
    "    return RM_CIs\n"
   ],
   "id": "1425e30ecd97044b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:54:15.598638Z",
     "start_time": "2025-03-24T06:54:00.449356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "image = images[i]\n",
    "label = labels[i]\n",
    "\n",
    "\n",
    "RM_CIs = process_image(image, label, i)"
   ],
   "id": "618909eaffcfccfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "LayerRGB_convs_1_RM: torch.Size([225, 3, 3])\n",
      "LayerRGB_convs_2_RM: torch.Size([625, 3, 1])\n",
      "Gray_convs_0_RM: torch.Size([70, 6, 6])\n",
      "LayerGray_convs_1_RM: torch.Size([625, 3, 3])\n",
      "LayerGray_convs_2_RM: torch.Size([1225, 3, 1])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:54:21.457835Z",
     "start_time": "2025-03-24T06:54:21.445801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, RM_CI in RM_CIs.items():\n",
    "    print(f\"{name}, {RM_CI.shape}\")"
   ],
   "id": "6580e287d0604b31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB_convs_0, torch.Size([6, 6, 5, 5, 3])\n",
      "RGB_convs_1, torch.Size([3, 3, 10, 10, 3])\n",
      "RGB_convs_2, torch.Size([3, 1, 10, 30, 3])\n",
      "Gray_convs_0, torch.Size([6, 6, 5, 5, 1])\n",
      "Gray_convs_1, torch.Size([3, 3, 10, 10, 1])\n",
      "Gray_convs_2, torch.Size([3, 1, 10, 30, 1])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:56:10.345109Z",
     "start_time": "2025-03-24T06:56:10.335030Z"
    }
   },
   "cell_type": "code",
   "source": [
    " heatmap_layers = {\n",
    "        # 'RGB_convs_0': model.RGB_convs[1],\n",
    "        'RGB_convs_1': model.RGB_convs[2][1],\n",
    "        'RGB_convs_2': model.RGB_convs[3],\n",
    "        'Gray_convs_0': model.Gray_convs[0][1],\n",
    "        'Gray_convs_1': model.Gray_convs[2][1],\n",
    "        'Gray_convs_2': model.Gray_convs[3]\n",
    "    }"
   ],
   "id": "96366f65ca0e9da8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:56:11.170687Z",
     "start_time": "2025-03-24T06:56:11.037873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from plot_cam import get_cam_target_layers, get_each_layers_cam\n",
    "\n",
    "# 定義所有要使用的 CAM 方法\n",
    "# cam_methods = [GradCAM, HiResCAM, GradCAMPlusPlus, GradCAMElementWise, XGradCAM, AblationCAM,\n",
    "#                    ScoreCAM, EigenCAM, EigenGradCAM, LayerCAM, KPCA_CAM]\n",
    "# 如果只想測試部分方法,可以使用下面這行\n",
    "cam_methods = [GradCAM]\n",
    "\n",
    "# 對每個 CAM 方法進行處理\n",
    "for method in cam_methods:\n",
    "    print(f\"drawing {method.__name__}\")\n",
    "    # 獲取需要生成 CAM 的目標層\n",
    "\n",
    "\n",
    "    # 對每一層生成 CAM (Class Activation Map)\n",
    "    cams = get_each_layers_cam(\n",
    "        model=model,\n",
    "        target_layers=heatmap_layers,\n",
    "        label=label.argmax().item(),\n",
    "        input_tensor=image,\n",
    "        cam_method=method)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "fd6908dd01a10c70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing GradCAM\n",
      "{'RGB_convs_1': cReLU_percent(percent=0.4000000059604645), 'RGB_convs_2': Sequential(\n",
      "  (0): RBF_Conv2d(initial = kaiming, weight shape = (625, 225, 1, 1))\n",
      "  (1): cReLU_percent(percent=0.5)\n",
      "), 'Gray_convs_0': cReLU_percent(percent=0.30000001192092896), 'Gray_convs_1': cReLU_percent(percent=0.4000000059604645), 'Gray_convs_2': Sequential(\n",
      "  (0): RBF_Conv2d(initial = kaiming, weight shape = (1225, 625, 1, 1))\n",
      "  (1): cReLU_percent(percent=0.5)\n",
      ")}\n",
      "layer RGB_convs_1\n",
      "target cReLU_percent(percent=0.4000000059604645)\n",
      "layer RGB_convs_2\n",
      "target Sequential(\n",
      "  (0): RBF_Conv2d(initial = kaiming, weight shape = (625, 225, 1, 1))\n",
      "  (1): cReLU_percent(percent=0.5)\n",
      ")\n",
      "layer Gray_convs_0\n",
      "target cReLU_percent(percent=0.30000001192092896)\n",
      "layer Gray_convs_1\n",
      "target cReLU_percent(percent=0.4000000059604645)\n",
      "layer Gray_convs_2\n",
      "target Sequential(\n",
      "  (0): RBF_Conv2d(initial = kaiming, weight shape = (1225, 625, 1, 1))\n",
      "  (1): cReLU_percent(percent=0.5)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:56:26.391264Z",
     "start_time": "2025-03-24T06:56:26.380756Z"
    }
   },
   "cell_type": "code",
   "source": " heatmap_layers",
   "id": "170612b2372fc468",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RGB_convs_1': cReLU_percent(percent=0.4000000059604645),\n",
       " 'RGB_convs_2': Sequential(\n",
       "   (0): RBF_Conv2d(initial = kaiming, weight shape = (625, 225, 1, 1))\n",
       "   (1): cReLU_percent(percent=0.5)\n",
       " ),\n",
       " 'Gray_convs_0': cReLU_percent(percent=0.30000001192092896),\n",
       " 'Gray_convs_1': cReLU_percent(percent=0.4000000059604645),\n",
       " 'Gray_convs_2': Sequential(\n",
       "   (0): RBF_Conv2d(initial = kaiming, weight shape = (1225, 625, 1, 1))\n",
       "   (1): cReLU_percent(percent=0.5)\n",
       " )}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T06:57:09.658798Z",
     "start_time": "2025-03-24T06:57:09.651276Z"
    }
   },
   "cell_type": "code",
   "source": "model.RGB_convs[0]",
   "id": "39c70e12e2610e89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): RGB_Conv2d(initial = uniform, weight shape = torch.Size([30, 3]), cal_dist = LAB)\n",
       "  (1): triangle(w = 1.0)\n",
       "  (2): cReLU_percent(percent=0.30000001192092896)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "eca9e17f81a82146"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
